import streamlit as st
import pandas as pd
import base64
import time
import random
from io import BytesIO
from gtts import gTTS

# ==========================================
# 1. æ ¸å¿ƒé…ç½®èˆ‡ CSS (å®Œå…¨èåˆæ­£å¼ç‰ˆé¢¨æ ¼)
# ==========================================
st.set_page_config(page_title="Etymon Decoder v2.5", page_icon="ğŸ§©", layout="wide")

def inject_custom_css():
    st.markdown("""
        <style>
            html { font-size: 18px; }
            .responsive-word { font-size: 5rem !important; font-weight: 800; color: #1E88E5; text-align: center; }
            .responsive-phonetic { font-size: 1.5rem !important; color: #666; text-align: center; margin-bottom: 20px; }
            .vibe-box {
                background-color: #f0f7ff; padding: 25px; border-left: 10px solid #1E88E5;
                border-radius: 15px; margin: 20px 0; animation: fadeIn 0.8s;
            }
            .breakdown-container {
                font-family: 'Courier New', monospace; font-size: 1.8rem; background: #262730;
                color: white; padding: 15px 30px; border-radius: 50px; display: inline-block; margin: 20px 0;
            }
            @keyframes fadeIn { from { opacity: 0; transform: translateY(10px); } to { opacity: 1; transform: translateY(0); } }
        </style>
    """, unsafe_allow_html=True)

# ==========================================
# 2. å·¥å…·å‡½å¼ (éŸ³è¨Šèˆ‡ 20 æ¬„è®€å–)
# ==========================================

def speak(text, key_suffix=""):
    try:
        if not text: return
        tts = gTTS(text=text, lang='en')
        fp = BytesIO()
        tts.write_to_fp(fp)
        audio_base64 = base64.b64encode(fp.getvalue()).decode()
        unique_id = f"audio_{int(time.time())}_{key_suffix}"
        st.components.v1.html(f'<audio id="{unique_id}" autoplay="true" style="display:none;"><source src="data:audio/mp3;base64,{audio_base64}" type="audio/mp3"></audio><script>document.getElementById("{unique_id}").play();</script>', height=0)
    except Exception as e: st.error(f"èªéŸ³éŒ¯èª¤: {e}")

@st.cache_data(ttl=60)
def load_db():
    COL_NAMES = [
        'category', 'roots', 'meaning', 'word', 'breakdown', 
        'definition', 'phonetic', 'example', 'translation', 'native_vibe',
        'synonym_nuance', 'visual_prompt', 'social_status', 'emotional_tone', 'street_usage',
        'collocation', 'etymon_story', 'usage_warning', 'memory_hook', 'audio_tag'
    ]
    # æ­£å¼ç‰ˆç›´æ¥è®€å– A:T (20 æ¬„ä½)
    SHEET_ID = "W1ADPyf5gtGdpIEwkxBEsaJ0bksYldf4AugoXnq6Zvg"
    url = f'https://docs.google.com/spreadsheets/d/{SHEET_ID}/gviz/tq?tqx=out:csv&range=A:T'
    try:
        df = pd.read_csv(url)
        # å¼·åˆ¶å°é½Š 20 æ¬„
        if len(df.columns) < 20:
            for col in COL_NAMES[len(df.columns):]: df[col] = ""
        df.columns = COL_NAMES
        return df.dropna(subset=['word']).fillna("").reset_index(drop=True)
    except: return pd.DataFrame(columns=COL_NAMES)

# ==========================================
# 3. ç™¾ç§‘ç´šé¡¯ç¤ºçµ„ä»¶ (èåˆ native_vibe è§£é–é‚è¼¯)
# ==========================================

def show_encyclopedia_card(row):
    # --- é ‚éƒ¨ï¼šæ ¸å¿ƒå–®å­—å€ ---
    st.markdown(f"<div class='responsive-word'>{row['word']}</div>", unsafe_allow_html=True)
    st.markdown(f"<div class='responsive-phonetic'>/{row['phonetic']}/</div>", unsafe_allow_html=True)
    
    col_a, col_b = st.columns([1, 4])
    with col_a:
        if st.button("ğŸ”Š æœ—è®€å–®å­—", key=f"btn_{row['word']}"): speak(row['word'], row['word'])
    with col_b:
        st.markdown(f"<div class='breakdown-container'>{row['breakdown']}</div>", unsafe_allow_html=True)

    # --- ä¸­é–“ï¼šå®šç¾©èˆ‡å­—æ ¹ ---
    c1, c2 = st.columns(2)
    with c1:
        st.info(f"**ğŸ¯ å®šç¾©ï¼š** {row['definition']}")
        st.write(f"**ğŸ“ ä¾‹å¥ï¼š** {row['example']}")
        st.caption(f"ç¿»è­¯ï¼š{row['translation']}")
    with c2:
        st.success(f"**ğŸ’¡ å­—æ ¹ï¼š** {row['roots']} ({row['meaning']})")
        st.markdown(f"**ğŸª è¨˜æ†¶é»ï¼š** {row['memory_hook']}")

    # --- é—œéµï¼šèªæ„Ÿè§£é–é‚è¼¯ (æ­£å¼ç‰ˆç‰¹è‰²) ---
    if row['native_vibe']:
        if not st.session_state.get('vibe_unlocked', False):
            if st.button("ğŸ æ‹†é–‹èªæ„Ÿé©šå–œåŒ… (Unlock Native Vibe)", use_container_width=True, type="secondary"):
                st.session_state.vibe_unlocked = True
                st.balloons()
                st.rerun()
        else:
            st.markdown(f"""
                <div class='vibe-box'>
                    <h4 style='color:#1E88E5; margin-top:0;'>ğŸŒŠ æ¯èªäººå£«èªæ„Ÿ (Native Vibe)</h4>
                    <p style='font-style: italic; font-size: 1.1rem;'>{row['native_vibe']}</p>
                </div>
            """, unsafe_allow_html=True)

    # --- åº•éƒ¨ï¼šç™¾ç§‘æ“´å…… (Tabs) ---
    with st.expander("ğŸ“š æ›´å¤šæ·±åº¦ç™¾ç§‘è³‡è¨Š (å­—æºã€ç¤¾æœƒéšå±¤ã€æ„è±¡)"):
        tab_a, tab_b, tab_c = st.tabs(["ğŸ›ï¸ æ–‡åŒ–èˆ‡å­—æº", "ğŸ‘” ç¤¾æœƒæ„è±¡", "ğŸ˜ è¡—é ­å¯¦æˆ°"])
        with tab_a:
            st.write(f"**ğŸ“œ å­—æºæ•…äº‹ï¼š** {row['etymon_story']}")
            st.write(f"**âš–ï¸ åŒç¾©è©è¾¨æï¼š** {row['synonym_nuance']}")
        with tab_b:
            st.write(f"**ğŸ¨ è¦–è¦ºæ„è±¡ï¼š** {row['visual_prompt']}")
            st.write(f"**ğŸ‘” ç¤¾æœƒåœ°ä½æ„Ÿï¼š** {row['social_status']}")
            st.write(f"**ğŸŒ¡ï¸ æƒ…ç·’è‰²èª¿ï¼š** {row['emotional_tone']}")
        with tab_c:
            st.write(f"**ğŸ™ï¸ è¡—é ­ç”¨æ³•ï¼š** {row['street_usage']}")
            st.write(f"**ğŸ”— å¸¸ç”¨æ­é…ï¼š** {row['collocation']}")
            if row['usage_warning']:
                st.error(f"âš ï¸ è­¦å‘Šï¼š{row['usage_warning']}")

# ==========================================
# 4. é é¢æ•´åˆ
# ==========================================

def page_learn_search(df):
    st.title("ğŸ“– å­¸ç¿’èˆ‡æœå°‹")
    tab_card, tab_list = st.tabs(["éš¨æ©Ÿå–®å­—å¡", "è³‡æ–™åº«åˆ—è¡¨"])
    
    with tab_card:
        # åˆ†é¡éæ¿¾
        cats = ["å…¨éƒ¨"] + sorted(df['category'].unique().tolist())
        sel_cat = st.selectbox("é¸æ“‡åˆ†é¡", cats, key="cat_sel")
        f_df = df if sel_cat == "å…¨éƒ¨" else df[df['category'] == sel_cat]

        if not f_df.empty:
            if 'curr_w' not in st.session_state:
                st.session_state.curr_w = f_df.sample(1).iloc[0].to_dict()
                st.session_state.vibe_unlocked = False

            if st.button("ä¸‹ä¸€å€‹å–®å­— (Next Word) â”", use_container_width=True, type="primary"):
                st.session_state.curr_w = f_df.sample(1).iloc[0].to_dict()
                st.session_state.vibe_unlocked = False
                st.rerun()

            show_encyclopedia_card(st.session_state.curr_w)

    with tab_list:
        search = st.text_input("ğŸ” æœå°‹å–®å­—æˆ–ä¸­æ–‡...", placeholder="è¼¸å…¥é—œéµå­—...")
        if search:
            mask = df.apply(lambda r: search.lower() in str(r.values).lower(), axis=1)
            st.dataframe(df[mask][['word', 'definition', 'roots', 'category']], use_container_width=True)
        else:
            st.dataframe(df[['word', 'definition', 'roots', 'category']].head(50), use_container_width=True)

# ==========================================
# 4. é é¢é‚è¼¯ (Pages)
# ==========================================

def page_home(df):
    st.markdown("<h1 style='text-align: center;'>Etymon Decoder</h1>", unsafe_allow_html=True)
    st.write("---")
    c1, c2, c3 = st.columns(3)
    c1.metric("ç¸½å–®å­—é‡", len(df))
    c2.metric("åˆ†é¡ä¸»é¡Œ", df['category'].nunique())
    c3.metric("ç¨ç‰¹å­—æ ¹", df['roots'].nunique())
    st.info("ğŸ‘ˆ è«‹å¾å·¦å´é¸å–®é¸æ“‡ã€Œå­¸ç¿’èˆ‡æœå°‹ã€é–‹å§‹è§£ç¢¼ã€‚")

def page_learn_search(df):
    st.title("ğŸ“– å­¸ç¿’èˆ‡æœå°‹")
    
    # æœå°‹åŠŸèƒ½
    search_mode = st.radio("æ¨¡å¼", ["å¿«é€ŸæŸ¥è©¢", "éš¨æ©Ÿæ¢ç´¢"], horizontal=True)
    
    if search_mode == "å¿«é€ŸæŸ¥è©¢":
        search_word = st.selectbox("è«‹é¸æ“‡æˆ–è¼¸å…¥å–®å­—", [""] + sorted(df['word'].tolist()))
        if search_word:
            row = df[df['word'] == search_word].iloc[0]
            show_word_encyclopedia(row)
    else:
        if st.button("ğŸ² éš¨æ©Ÿä¾†ä¸€å€‹å–®å­—"):
            st.session_state.random_word = df.sample(1).iloc[0].to_dict()
        
        if 'random_word' in st.session_state:
            show_word_encyclopedia(st.session_state.random_word)

def page_quiz(df):
    st.title("ğŸ§  å­—æ ¹æŒ‘æˆ°è³½")
    cat = st.selectbox("æ¸¬é©—ç¯„åœ", df['category'].unique())
    pool = df[df['category'] == cat]
    
    if st.button("é–‹å§‹æ¸¬é©— / ä¸‹ä¸€é¡Œ"):
        st.session_state.q = pool.sample(1).iloc[0].to_dict()
        st.session_state.show_ans = False

    if 'q' in st.session_state:
        st.subheader("è«‹å•é€™å€‹å®šç¾©å°æ‡‰å“ªå€‹å–®å­—ï¼Ÿ")
        st.info(st.session_state.q['definition'])
        st.write(f"æç¤º (å­—æ ¹): {st.session_state.q['roots']}")
        
        if st.button("çœ‹ç­”æ¡ˆ"):
            st.session_state.show_ans = True
        
        if st.session_state.show_ans:
            st.success(f"ç­”æ¡ˆæ˜¯ï¼š{st.session_state.q['word']}")
            speak(st.session_state.q['word'], "quiz")
            st.write(f"çµæ§‹ï¼š{st.session_state.q['breakdown']}")

# ==========================================
# 5. ä¸»ç¨‹å¼å…¥å£
# ==========================================
def main():
    inject_custom_css()
    df = load_db()
    if df.empty: return

    page = st.sidebar.radio("å°èˆª", ["é¦–é ", "å­¸ç¿’èˆ‡æœå°‹", "æ¸¬é©—æ¨¡å¼"])
    
    if page == "é¦–é ": page_home(df)
    elif page == "å­¸ç¿’èˆ‡æœå°‹": page_learn_search(df)
    elif page == "æ¸¬é©—æ¨¡å¼": page_quiz(df)

if __name__ == "__main__":
    main()
