import streamlit as st
import json
import random
import os
import re

DB_FILE = 'etymon_database.json'

# --- 1. è‡ªå‹•è§£æå¼•æ“ (é—œéµåŠŸèƒ½) ---
def parse_raw_text(raw_text):
    """
    å°‡äººé¡é–±è®€çš„æ ¼å¼è‡ªå‹•è½‰ç‚ºçµæ§‹åŒ– JSON
    """
    new_data = []
    # åˆ‡åˆ†å¤§é¡
    categories = re.split(r'ã€Œ(.+?)ã€é¡', raw_text)
    
    for i in range(1, len(categories), 2):
        cat_name = categories[i]
        cat_content = categories[i+1]
        
        cat_obj = {"category": cat_name, "root_groups": []}
        
        # å°‹æ‰¾è©æ ¹å€å¡Š (ä¾‹å¦‚: -fac- / -fec- ...)
        root_blocks = re.split(r'\n(?=-)', cat_content)
        for block in root_blocks:
            root_match = re.search(r'-([\w/ \-]+)-\s*[\(ï¼ˆ](.+?)[\)ï¼‰]', block)
            if root_match:
                group = {
                    "roots": [r.strip() for r in root_match.group(1).split('/')],
                    "meaning": root_match.group(2).strip(),
                    "vocabulary": []
                }
                # å°‹æ‰¾å–®å­—è¡Œ (ä¾‹å¦‚: Factory (Fac åš + tory å ´æ‰€ = å·¥å» ))
                words = re.findall(r'(\w+[\-\w]*)\s*[\(ï¼ˆ](.+?)\s*=\s*(.+?)[\)ï¼‰]', block)
                for w_name, w_logic, w_trans in words:
                    group["vocabulary"].append({
                        "word": w_name.strip(),
                        "breakdown": w_logic.strip(),
                        "definition": w_trans.strip()
                    })
                if group["vocabulary"]:
                    cat_obj["root_groups"].append(group)
        new_data.append(cat_obj)
    return new_data

# --- 2. åŸºç¤åŠŸèƒ½ ---
def load_data():
    if os.path.exists(DB_FILE):
        with open(DB_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return []

def save_data(data):
    with open(DB_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=4, ensure_ascii=False)

# --- 3. é é¢é‚è¼¯ ---
st.set_page_config(page_title="è©æ ¹å®‡å®™ï¼šè‡ªå‹•è§£ç¢¼ç‰ˆ", layout="wide")

# å¯†ç¢¼é– (ä¿ç•™ä½ è¦æ±‚çš„å¯†ç¢¼åŠŸèƒ½)
if "authenticated" not in st.session_state:
    st.title("ğŸ” è©æ ¹å®‡å®™ç§æœ‰è¨ªå•")
    pwd = st.text_input("è¼¸å…¥è¨ªå•å¯†ç¢¼ï¼š", type="password")
    if st.button("ç™»å…¥"):
        if pwd == "8888":
            st.session_state.authenticated = True
            st.rerun()
        else:
            st.error("å¯†ç¢¼éŒ¯èª¤")
    st.stop()

data = load_data()
tab1, tab2, tab3 = st.tabs(["ğŸ” æœå°‹è§£ç¢¼", "âœï¸ å­¸ç¿’æ¸¬é©—", "âš™ï¸ æ•¸æ“šå·¥å» "])

with tab1:
    st.title("ğŸ§© è©æ ¹æœå°‹")
    query = st.text_input("è¼¸å…¥å–®å­—/è©æ ¹ï¼š")
    if query:
        q = query.lower()
        for cat in data:
            for group in cat['root_groups']:
                match = [v for v in group['vocabulary'] if q in v['word'].lower()]
                if any(q in r.lower() for r in group['roots']) or match:
                    st.success(f"è©æ ¹ï¼š{'/'.join(group['roots'])} | å«ç¾©ï¼š{group['meaning']}")
                    for v in group['vocabulary']:
                        st.write(f"**{v['word']}** â†’ `{v['breakdown']}` | {v['definition']}")

with tab2:
    st.title("âœï¸ è‡ªæˆ‘æ¸¬é©—")
    # ... (æ­¤è™•ä¿ç•™ä¹‹å‰çš„ random.choice æ¸¬é©—é‚è¼¯) ...

with tab3:
    st.title("âš™ï¸ æ•¸æ“šå·¥å»  (è‡ªå‹•æ‰“åŒ…)")
    st.markdown("### 1. ç›´æ¥è²¼ä¸Šæ–‡å­—")
    raw_input = st.text_area("ç›´æ¥è²¼ä¸Šæ–‡å­—æ ¼å¼ (ä¾‹å¦‚ï¼š-fac- åš...)", height=300)
    
    if st.button("ğŸš€ é–‹å§‹è‡ªå‹•è§£æä¸¦å„²å­˜"):
        if raw_input:
            structured_data = parse_raw_text(raw_input)
            save_data(structured_data)
            st.success("è§£ææˆåŠŸï¼æ•¸æ“šå·²æ‰“åŒ…ä¸¦å­˜å…¥è³‡æ–™åº«ã€‚")
            st.cache_data.clear()
    
    st.markdown("---")
    st.markdown("### 2. é€²éšï¼šæ‰‹å‹•æ ¡å° JSON")
    st.json(data)