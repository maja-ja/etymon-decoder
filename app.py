import streamlit as st
import json
import os
import random
import pandas as pd
from gtts import gTTS
import time
import base64
from io import BytesIO
from gtts import gTTS
from streamlit_gsheets import GSheetsConnection
# ==========================================
# 1. ä¿®æ­£èªéŸ³ç™¼éŸ³ (ç¢ºä¿æœ‰è²éŸ³ä¸” autoplay)
# ==========================================
def speak(text):
    try:
        # 1. ç”ŸæˆèªéŸ³
        tts = gTTS(text=text, lang='en')
        fp = BytesIO()
        tts.write_to_fp(fp)
        fp.seek(0)
        audio_bytes = fp.read()
        
        # 2. æ–¹æ³• Aï¼šä½¿ç”¨ HTML5 è‡ªå‹•æ’­æ”¾ï¼ˆåŸæœ¬çš„æ–¹æ³•ï¼Œä½†åŠ ä¸Šæ›´å¤šç›¸å®¹æ€§ä»£ç¢¼ï¼‰
        audio_base64 = base64.b64encode(audio_bytes).decode()
        audio_html = f"""
            <audio autoplay id="audio_tag">
                <source src="data:audio/mp3;base64,{audio_base64}" type="audio/mp3">
            </audio>
            <script>
                var audio = document.getElementById("audio_tag");
                audio.volume = 1.0;
                var promise = audio.play();
                if (promise !== undefined) {{
                    promise.catch(error => {{
                        console.log("Autoplay was prevented by browser settings.");
                    }});
                }}
            </script>
            """
        st.components.v1.html(audio_html, height=0)
        
        # 3. æ–¹æ³• Bï¼šåœ¨å´é‚Šæ¬„é¡¯ç¤ºä¸€å€‹è¿·ä½ çš„æ’­æ”¾å™¨ï¼ˆå‚™æ¡ˆï¼Œå¦‚æœè‡ªå‹•æ’­æ”¾å¤±æ•ˆï¼Œä½¿ç”¨è€…å¯é»æ“Šé€™è£¡ï¼‰
        with st.sidebar:
            st.audio(audio_bytes, format="audio/mp3")
            
    except Exception as e:
        st.error(f"èªéŸ³ç”Ÿæˆå¤±æ•—: {e}")
# ==========================================
# 1. æ ¸å¿ƒé…ç½®èˆ‡é›²ç«¯åŒæ­¥
# ==========================================

# é€™æ˜¯ä½ åŸæœ¬ã€Œå”¯è®€ã€çš„å–®å­—åº«è³‡æ–™ä¾†æº
SHEET_ID = '1Gs0FX7c8bUQTnSytX1EqjMLATeVc30GmdjSOYW_sYsQ'
GSHEET_URL = f'https://docs.google.com/spreadsheets/d/{SHEET_ID}/gviz/tq?tqx=out:csv'
PENDING_FILE = 'pending_data.json'
# é€™æ˜¯ä½ è¦ã€Œå¯«å…¥ã€å›å ±çš„ç›®æ¨™ç¶²å€ (å¾ secrets è®€å–)
FEEDBACK_URL = st.secrets.get("feedback_sheet_url")
@st.cache_data(ttl=600)
def load_db():
    import string
    # A=0, B=11, C=22, D=33... é€™æ˜¯å°æ‡‰æ‚¨ A-Z æ©«å‘ä¸¦æ’çš„ç´¢å¼•
    ALPHABET = list(string.ascii_uppercase)
    BLOCK_MAP = {letter: i * 11 for i, letter in enumerate(ALPHABET)}
    
    try:
        # è®€å–å®Œæ•´è©¦ç®—è¡¨ï¼Œç¢ºä¿ä¸æ¼æ‰ä»»ä½•æ¬„ä½
        raw_df = pd.read_csv(GSHEET_URL)
        if raw_df.empty:
            return []
    except Exception as e:
        st.error(f"è®€å–è©¦ç®—è¡¨å¤±æ•—: {e}")
        return []

    structured_data = []
    total_word_count = 0

    for letter, start_idx in BLOCK_MAP.items():
        # æª¢æŸ¥è©²å€å¡Šæ˜¯å¦å­˜åœ¨æ–¼è©¦ç®—è¡¨ä¸­
        if start_idx + 3 >= len(raw_df.columns): 
            continue
            
        try:
            # æ“·å–è©²å­—æ¯å€å¡Šçš„ 9 æ¬„
            df_part = raw_df.iloc[:, start_idx:start_idx+9].copy()
            df_part.columns = [
                'category', 'roots', 'meaning', 'word', 
                'breakdown', 'definition', 'phonetic', 'example', 'translation'
            ]
            
            # æ¸…ç†è³‡æ–™ï¼šç§»é™¤æ¨™é¡Œè¡Œï¼Œä¸¦ç¢ºä¿ 'word' æ¬„ä½æœ‰å…§å®¹
            df_part = df_part[df_part['word'].notna()]
            df_part = df_part[df_part['word'].astype(str).str.lower() != 'word']
            df_part = df_part[df_part['category'].astype(str).str.lower() != 'category']

            if df_part.empty:
                continue

            sub_cats = []
            # ç¬¬ä¸€å±¤ï¼šä¾æ“š Category (å°åˆ†æ”¯) åˆ†çµ„
            for cat_name, cat_group in df_part.groupby('category'):
                root_groups = []
                # ç¬¬äºŒå±¤ï¼šä¾æ“š Roots åˆ†çµ„
                for (roots, meaning), group_df in cat_group.groupby(['roots', 'meaning']):
                    vocabulary = []
                    for _, row in group_df.iterrows():
                        word_val = str(row['word']).strip()
                        if word_val and word_val.lower() != 'nan':
                            vocabulary.append({
                                "word": word_val,
                                "breakdown": str(row['breakdown']),
                                "definition": str(row['definition']),
                                "phonetic": str(row['phonetic']),
                                "example": str(row['example']),
                                "translation": str(row['translation'])
                            })
                            total_word_count += 1
                    
                    if vocabulary:
                        root_groups.append({
                            "roots": [r.strip() for r in str(roots).split('/')],
                            "meaning": str(meaning),
                            "vocabulary": vocabulary
                        })
                
                if root_groups:
                    sub_cats.append({
                        "name": str(cat_name),
                        "root_groups": root_groups
                    })
            
            if sub_cats:
                structured_data.append({
                    "letter": letter,
                    "sub_categories": sub_cats
                })
        except Exception:
            continue
            
    return structured_data
def save_feedback_to_gsheet(word, feedback_type, comment):
    try:
        # 1. å»ºç«‹é€£ç·š
        conn = st.connection("gsheets", type=GSheetsConnection)
        
        # 2. å¼·åˆ¶ä¸ä½¿ç”¨å¿«å–è®€å–è³‡æ–™ (ttl=0)
        df = conn.read(spreadsheet=FEEDBACK_URL, ttl=0)
        
        # 2. å»ºç«‹æ–°è³‡æ–™åˆ—
        new_row = pd.DataFrame([{
            "timestamp": pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S"),
            "word": word,
            "type": feedback_type,
            "comment": comment,
            "status": "pending"
        }])
        
        # 3. åˆä½µä¸¦æ›´æ–°
        updated_df = pd.concat([df, new_row], ignore_index=True)
        
        # 4. åŸ·è¡Œå¯«å…¥ (é—œéµï¼šé€™ä¸€æ­¥éœ€è¦ Service Account æ¬Šé™)
        conn.update(spreadsheet=FEEDBACK_URL, data=updated_df)
        
        st.success(f"âœ… å–®å­—ã€Œ{word}ã€çš„å›å ±å·²åŒæ­¥è‡³é›²ç«¯ï¼")
        
    except Exception as e:
        # å¦‚æœé‚„æ˜¯å™´éŒ¯ï¼Œé¡¯ç¤ºæ›´è©³ç´°çš„è¨Šæ¯
        st.error(f"âŒ é›²ç«¯åŒæ­¥å¤±æ•—ã€‚")
        st.info("è«‹æª¢æŸ¥ Streamlit Cloud çš„ Secrets æ˜¯å¦å·²åŒ…å«å®Œæ•´çš„ [connections.gsheets] å€æ®µå…§å®¹ã€‚")
        st.caption(f"éŒ¯èª¤è©³æƒ…: {e}")
def get_stats(data):
    """è¨ˆç®—å–®å­—ç¸½æ•¸"""
    if not data: return 0, 0
    total_words = sum(len(g.get('vocabulary', [])) for cat in data for g in cat.get('root_groups', []))
    return len(data), total_words
# ==========================================
# 2. é€šç”¨èˆ‡å°ˆæ¥­å€åŸŸçµ„ä»¶
# ==========================================
def render_word_card(v, theme_color="#1E88E5"):
    """
    çµ±ä¸€çš„å–®å­—å¡æ¸²æŸ“å‡½å¼
    v: å–®å­—è³‡æ–™å­—å…¸
    theme_color: å¡ç‰‡æ¨™é¡Œé¡è‰²
    """
    with st.container(border=True):
        col_w, col_p = st.columns([4, 1])
        with col_w:
            st.markdown(f'<div style="font-size: 1.5em; font-weight: bold; color: {theme_color};">{v["word"]}</div>', unsafe_allow_html=True)
            if v.get('phonetic') and str(v['phonetic']) != "nan": 
                st.caption(f"/{v['phonetic']}/")
        with col_p:
            # ä½¿ç”¨éš¨æ©Ÿ key é¿å…åœ¨åŒé é¢å‡ºç¾é‡è¤‡ ID å°è‡´æŒ‰éˆ•å¤±æ•ˆ
            btn_key = f"btn_{v['word']}_{random.randint(0, 100000)}"
            if st.button("ğŸ”Š", key=btn_key): 
                speak(v['word'])
        
        st.markdown(f"**æ‹†è§£ï¼š** `{v['breakdown']}`")
        st.markdown(f"**å®šç¾©ï¼š** {v['definition']}")
        
        if v.get('example') and str(v['example']) != "nan":
            with st.expander("æŸ¥çœ‹ä¾‹å¥"):
                st.write(v['example'])
                if v.get('translation') and str(v['translation']) != "nan":
                    st.caption(f"({v['translation']})")
def ui_feedback_component(word):
    """å–®å­—éŒ¯èª¤å›å ±å½ˆçª—"""
    with st.popover("éŒ¯èª¤å›å ±"):
        st.write(f"å›å ±å–®å­—ï¼š**{word}**")
        f_type = st.selectbox("éŒ¯èª¤é¡å‹", ["ç™¼éŸ³éŒ¯èª¤", "æ‹†è§£æœ‰èª¤", "ä¸­æ–‡é‡‹ç¾©éŒ¯èª¤", "åˆ†é¡éŒ¯èª¤", "å…¶ä»–"], key=f"err_type_{word}")
        f_comment = st.text_area("è©³ç´°èªªæ˜", placeholder="è«‹æè¿°æ­£ç¢ºçš„è³‡è¨Š...", key=f"err_note_{word}")
        
        if st.button("æäº¤å›å ±", key=f"err_btn_{word}"):
            if f_comment.strip() == "":
                st.error("è«‹å¡«å¯«èªªæ˜å…§å®¹")
            else:
                save_feedback_to_gsheet(word, f_type, f_comment)
                st.success("æ„Ÿè¬å›å ±ï¼ç®¡ç†å“¡å°‡æœƒç›¡å¿«ä¿®æ­£ã€‚")
def ui_quiz_page(data):
    st.title("å­¸ç¿’å€ (Flashcards)")
    
    # --- æ ¸å¿ƒä¿®æ­£ï¼šå°‡åµŒå¥—è³‡æ–™æ‹‰å¹³ ---
    pool = []
    for block in data:
        for sub in block.get('sub_categories', []):
            for group in sub.get('root_groups', []):
                for v in group.get('vocabulary', []):
                    # åŠ å…¥æ‰€å±¬åˆ†é¡è³‡è¨Šä»¥ä¾¿é¡¯ç¤º
                    item = v.copy()
                    item['cat'] = sub['name']
                    pool.append(item)
    
    if not pool:
        st.warning("ç›®å‰è³‡æ–™åº«ä¸­æ²’æœ‰å–®å­—å¯ä¾›ç·´ç¿’ã€‚")
        return

    # åˆå§‹åŒ–æ¸¬é©—ç‹€æ…‹
    if 'flash_q' not in st.session_state:
        st.session_state.flash_q = random.choice(pool)
        st.session_state.flipped = False

    q = st.session_state.flash_q
    
    # é¡¯ç¤ºå¡ç‰‡æ­£é¢
    st.info(f"ğŸ“ åˆ†é¡ç¯„ç–‡ï¼š{q['cat']}")
    st.markdown(f"""
        <div style="text-align: center; padding: 40px; border: 2px solid #1E88E5; border-radius: 20px; background: #f9f9f9;">
            <h1 style="font-size: 4em; color: #1E88E5; margin: 0;">{q['word']}</h1>
        </div>
    """, unsafe_allow_html=True)

    # æŒ‰éˆ•åˆ—
    c1, c2, c3 = st.columns(3)
    if c1.button("ğŸ‘€ æŸ¥çœ‹ç­”æ¡ˆ", use_container_width=True):
        st.session_state.flipped = True
    if c2.button("ğŸ”Š æ’­æ”¾ç™¼éŸ³", use_container_width=True):
        speak(q['word'])
    if c3.button("â¡ï¸ ä¸‹ä¸€é¡Œ", use_container_width=True):
        st.session_state.flash_q = random.choice(pool)
        st.session_state.flipped = False
        st.rerun()

    # é¡¯ç¤ºèƒŒé¢ç­”æ¡ˆ
    if st.session_state.get('flipped'):
        st.markdown("---")
        st.success(f"**æ§‹æˆæ‹†è§£ï¼š** {q['breakdown']}")
        st.write(f"**é‡‹ç¾©å®šç¾©ï¼š** {q['definition']}")
        if q.get('example') and q['example'] != "nan":
            st.info(f"**ä¾‹å¥ç·´ç¿’ï¼š** {q['example']}")
            if q.get('translation') and q['translation'] != "nan":
                st.caption(f"({q['translation']})")
def ui_search_page(data, selected_cat):
    st.title("æœå°‹èˆ‡ç€è¦½")
    relevant = data if selected_cat == "å…¨éƒ¨é¡¯ç¤º" else [c for c in data if c['category'] == selected_cat]
    query = st.text_input("æœå°‹å–®å­—æˆ–å­—æ ¹...").strip().lower()
    for cat in relevant:
        for group in cat.get('root_groups', []):
            matched = [v for v in group['vocabulary'] if query in v['word'].lower() or any(query in r.lower() for r in group['roots'])]
            if matched:
                with st.expander(f"{'/'.join(group['roots'])} ({group['meaning']})", expanded=bool(query)):
                    for v in matched:
                        st.markdown(f"**{v['word']}** [{v['breakdown']}]: {v['definition']}")
def ui_admin_page(data):
    st.title("ğŸ›¡ï¸ ç®¡ç†å€ (Cloud Admin)")
    
    # 1. å¯†ç¢¼é©—è­‰ (ä½¿ç”¨ st.secrets)
    correct_password = st.secrets.get("admin_password", "8787")
    if not st.session_state.get('admin_auth'):
        pw_input = st.text_input("ç®¡ç†å“¡å¯†ç¢¼", type="password")
        if pw_input == correct_password:
            st.session_state.admin_auth = True
            st.rerun()
        elif pw_input != "":
            st.error("å¯†ç¢¼éŒ¯èª¤")
        return

    # 2. æ•¸æ“šçµ±è¨ˆ
    st.metric("è³‡æ–™åº«å–®å­—ç¸½é‡", f"{get_stats(data)[1]} å–®å­—")
    
    # 3. å‚™ä»½åŠŸèƒ½
    if st.button("æ‰‹å‹•å‚™ä»½ CSV (ä¸‹è¼‰å®Œæ•´å–®å­—åº«)"):
        flat = [{"category": c['category'], "roots": "/".join(g['roots']), "meaning": g['meaning'], **v} 
                for c in data for g in c['root_groups'] for v in g['vocabulary']]
        st.download_button("ç¢ºèªä¸‹è¼‰ CSV", pd.DataFrame(flat).to_csv(index=False).encode('utf-8-sig'), "etymon_backup.csv")

    st.divider()

    # 4. è®€å–é›²ç«¯å›å ± (å–ä»£èˆŠçš„ PENDING_FILE é‚è¼¯)
    st.subheader("ğŸ“ é›²ç«¯å¾…è™•ç†å›å ±")
    try:
        conn = st.connection("gsheets", type=GSheetsConnection)
        # ä½¿ç”¨ä½ åœ¨ Section 1 å®šç¾©çš„ FEEDBACK_URL
        df_pending = conn.read(spreadsheet=FEEDBACK_URL)
        
        if not df_pending.empty:
            st.dataframe(df_pending, use_container_width=True)
            
            st.info("ğŸ’¡ æç¤ºï¼šå¦‚éœ€ä¿®æ”¹æˆ–åˆªé™¤å›å ±ï¼Œè«‹ç›´æ¥å‰å¾€ Google Sheets é€²è¡Œæ“ä½œã€‚")
            if st.button("é‡æ–°æ•´ç†é›²ç«¯æ•¸æ“š"):
                st.rerun()
        else:
            st.info("ç›®å‰æ²’æœ‰å¾…è™•ç†çš„å›å ±ã€‚")
    except Exception as e:
        st.error(f"è®€å–é›²ç«¯å›å ±å¤±æ•—ï¼Œè«‹æª¢æŸ¥ Service Account æ¬Šé™èˆ‡ FEEDBACK_URLã€‚")
        st.caption(f"éŒ¯èª¤è©³æƒ…: {e}")

    # 5. ç™»å‡º
    if st.sidebar.button("ç™»å‡ºç®¡ç†å€"):
        st.session_state.admin_auth = False
        st.rerun()
# ==========================================
# 3. ä¸»ç¨‹åºå…¥å£
# ==========================================
def main():
    st.set_page_config(page_title="Etymon Decoder", layout="wide")
    data = load_db()
    
    # 1. è¨ˆç®—ç¸½å­—æ•¸ (éè¿´åµŒå¥—çµæ§‹)
    total_words = 0
    for block in data:
        for sub in block['sub_categories']:
            for group in sub['root_groups']:
                total_words += len(group['vocabulary'])
    
    # 2. å´é‚Šæ¬„é…ç½®
    st.sidebar.title("Etymon Decoder")
    menu = st.sidebar.radio("å°èˆª", ["å­—æ ¹å€", "æœå°‹", "å­¸ç¿’å€", "é«˜ä¸­ 7000 å€", "é†«å­¸å€", "æ³•å¾‹å€", "ç®¡ç†å€"])
    st.sidebar.divider()
    if st.sidebar.button("å¼·åˆ¶åˆ·æ–°é›²ç«¯æ•¸æ“š", use_container_width=True): 
        st.cache_data.clear()
        st.rerun()
    
    st.sidebar.metric("è³‡æ–™åº«ç¸½è¨ˆ", f"{total_words} Words")

    # 3. é é¢é‚è¼¯
    if menu == "æœå°‹":
        st.title("ğŸ” å…¨åŸŸå–®å­—æœå°‹")
        query = st.text_input("è¼¸å…¥å–®å­—ã€å­—æ ¹æˆ–ä¸­æ–‡é—œéµå­—", "").strip().lower()

        if query:
            results = []
            for block in data:
                for sub in block.get('sub_categories', []):
                    for group in sub.get('root_groups', []):
                        for v in group.get('vocabulary', []):
                            # å¤šæ¬„ä½æª¢ç´¢é‚è¼¯
                            content_to_search = (
                                str(v['word']) + 
                                str(v['definition']) + 
                                str(v.get('translation', '')) + 
                                str(group['roots'])
                            ).lower()
                            
                            if query in content_to_search:
                                results.append({
                                    "data": v,
                                    "cat": sub['name'],
                                    "root_info": f"{'/'.join(group['roots'])} ({group['meaning']})"
                                })

            if results:
                st.write(f"æ‰¾åˆ° {len(results)} å€‹ç›¸é—œçµæœï¼š")
                for item in results:
                    # æœå°‹çµæœçš„æ¨™é¡Œå±•é–‹
                    with st.expander(f"ğŸ“– {item['data']['word']} (åˆ†é¡ï¼š{item['cat']})"):
                        st.caption(f"å­—æ ¹ä¾†æºï¼š{item['root_info']}")
                        # --- ä¿®æ­£è™•ï¼šç¢ºä¿åªå‚³å…¥ 2 å€‹åƒæ•¸ ---
                        render_word_card(item['data'], theme_color="#1E88E5")
            else:
                st.info("æŸ¥ç„¡çµæœï¼Œè«‹å˜—è©¦å…¶ä»–é—œéµå­—ã€‚")
    elif menu == "å­—æ ¹å€":
        st.title("ğŸ—‚ï¸ å­—æ ¹ç¸½è¦½ (A-Z å¤§å€)")
        if not data:
            st.warning("ç›®å‰è®€å–ä¸åˆ°è³‡æ–™ã€‚è«‹ç¢ºèªè©¦ç®—è¡¨ Aã€Lã€W æ¬„ç­‰èµ·å§‹ä½æ˜¯å¦æœ‰å…§å®¹ã€‚")
            return

        for block in data:
            block_count = sum(len(g['vocabulary']) for s in block['sub_categories'] for g in s['root_groups'])
            with st.expander(f"âœ¨ å­—æ¯å€å¡Šï¼š{block['letter']} (å…± {block_count} å­—)"):
                for sub in block['sub_categories']:
                    st.markdown(f"#### ğŸ“‚ åˆ†é¡ï¼š{sub['name']}")
                    for group in sub['root_groups']:
                        st.info(f"**å­—æ ¹ï¼š** {' / '.join(group['roots'])} ({group['meaning']})")
                        # è½‰æ›ç‚ºè¡¨æ ¼é¡¯ç¤º
                        display_df = []
                        for v in group['vocabulary']:
                            display_df.append({
                                "å–®å­—": v['word'],
                                "æ‹†è§£": v['breakdown'],
                                "è§£é‡‹": v['definition'],
                                "ç¿»è­¯": v['translation']
                            })
                        if display_df:
                            st.table(display_df)
                    st.divider()
    elif menu == "å­¸ç¿’å€":
        ui_quiz_page(data)

    elif menu == "ç®¡ç†å€":

        st.title("ğŸ› ï¸ ç®¡ç†å“¡æ§åˆ¶å°")

        

        # å»ºç«‹ä¸€å€‹ç°¡å–®çš„å¯†ç¢¼æª¢æŸ¥ä»‹é¢

        password = st.text_input("è«‹è¼¸å…¥ç®¡ç†å“¡å¯†ç¢¼", type="password")

        

        # é€™è£¡è¨­å®šæ‚¨çš„å¯†ç¢¼ (å»ºè­°å¯¦éš›ä½¿ç”¨æ™‚å­˜æ”¾åœ¨ st.secrets)

        ADMIN_PASSWORD = st.secrets["admin_password"]

        

        if password == ADMIN_PASSWORD:

            st.success("é©—è­‰æˆåŠŸï¼")

            st.write("### æ ¸å¿ƒè³‡æ–™åº«çµæ§‹æ¸…å–® (JSON)")

            st.write("ç›®å‰çš„è³‡æ–™æ˜¯ç”± A-Z æ©«å‘å€å¡Šè®€å–ï¼Œä¸¦è‡ªå‹•åˆ†é¡ã€‚")

            

            # é¡¯ç¤ºå®Œæ•´çš„è³‡æ–™çµæ§‹ä¾›åµéŒ¯

            st.json(data)

            

            # ä¹Ÿå¯ä»¥åŠ å…¥æ•¸æ“šå°å‡ºåŠŸèƒ½

            st.download_button(

                label="ä¸‹è¼‰å®Œæ•´è³‡æ–™åº« (JSON)",

                data=json.dumps(data, indent=4, ensure_ascii=False),

                file_name="etymon_db_backup.json",

                mime="application/json"

            )

        elif password == "":

            st.info("è«‹è¼¸å…¥å¯†ç¢¼ä»¥å­˜å–å¾Œå°è³‡æ–™ã€‚")

        else:

            st.error("å¯†ç¢¼éŒ¯èª¤ï¼Œå­˜å–è¢«æ‹’ã€‚")

    else:
        # é€šç”¨ç¯©é¸é‚è¼¯ï¼šé©ç”¨æ–¼ é†«å­¸å€ã€æ³•å¾‹å€ã€é«˜ä¸­ 7000 å€ç­‰
        keyword = menu.replace(" å€", "").strip()
        st.title(f"ğŸ” {menu}")
        
        found_any = False
        for block in data:
            for sub in block.get('sub_categories', []):
                # åˆ¤æ–·é¸å–®é—œéµå­—æ˜¯å¦åœ¨åˆ†é¡åç¨±ä¸­
                if keyword in sub['name']:
                    found_any = True
                    st.subheader(f"ğŸ“‚ {sub['name']}")
                    for group in sub['root_groups']:
                        st.success(f"**å­—æ ¹ï¼š** {' / '.join(group['roots'])} ({group['meaning']})")
                        for v in group['vocabulary']:
                # --- ä¿®æ­£è™•ï¼šçµ±ä¸€åƒæ•¸ ---
                            render_word_card(v, theme_color="#1E88E5")
        if not found_any:
            st.info(f"ç›®å‰åœ¨ A-Z è³‡æ–™åº«ä¸­ï¼Œå°šæœªç™¼ç¾æ¨™è¨˜ç‚ºã€Œ{keyword}ã€çš„åˆ†é¡å…§å®¹ã€‚")
if __name__ == "__main__":
    main()
